{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:06:00 into the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# Create the training set of bigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    print(ch1, ch2)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix1)\n",
    "    # N[ix1, ix2] += 1\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5065, -1.6001,  0.1543, -1.5038,  0.6003,  0.1293,  0.3801,  0.9329,\n",
       "         -0.1734,  1.0973, -0.7667, -0.4664, -1.5550,  0.6321, -0.8354, -1.0189,\n",
       "          0.9538,  1.0722, -0.1760,  1.7314, -0.5848,  0.6770, -0.1518,  0.4151,\n",
       "         -1.7621, -0.8457,  1.6124],\n",
       "        [-0.0786,  0.4371,  1.6178,  0.8398, -1.1630,  0.5914, -0.7581, -0.9462,\n",
       "         -0.8864,  0.0635, -0.2182, -1.1287, -1.6756,  0.8278, -0.3998, -0.3225,\n",
       "          1.6548,  0.9399, -0.0143,  0.5533,  0.1249,  1.9361,  0.8274, -1.9637,\n",
       "         -0.0043,  0.2374, -0.3217],\n",
       "        [ 0.0624, -0.8057,  0.7439,  0.0466, -0.3992,  0.2192,  0.1475, -0.5697,\n",
       "         -0.5436,  1.0771, -0.9591,  1.6696, -1.1074, -0.3922, -1.1530,  1.6938,\n",
       "         -0.6793,  1.5330, -0.1629,  0.3364, -0.3267, -0.3821, -1.7494, -1.2651,\n",
       "          0.3915, -0.9126, -0.5953],\n",
       "        [ 0.0624, -0.8057,  0.7439,  0.0466, -0.3992,  0.2192,  0.1475, -0.5697,\n",
       "         -0.5436,  1.0771, -0.9591,  1.6696, -1.1074, -0.3922, -1.1530,  1.6938,\n",
       "         -0.6793,  1.5330, -0.1629,  0.3364, -0.3267, -0.3821, -1.7494, -1.2651,\n",
       "          0.3915, -0.9126, -0.5953],\n",
       "        [-0.9424,  0.3913,  0.3965,  0.1180, -0.1165, -0.3077,  0.8580,  0.5568,\n",
       "          0.3089,  0.0948,  0.1936,  1.3374, -0.1929, -0.1252, -0.7050, -0.0737,\n",
       "          0.2394, -1.3049, -1.2577, -0.6524,  0.8430, -0.9492,  1.1672,  1.6789,\n",
       "          1.2872, -2.9286,  2.2680]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @ this is a matrix multiplication operator in pytorch\n",
    "\n",
    "W = torch.randn((27, 27))\n",
    "xenc @ W  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0153, 0.0051, 0.0295, 0.0056, 0.0462, 0.0288, 0.0370, 0.0644, 0.0213,\n",
       "         0.0759, 0.0118, 0.0159, 0.0053, 0.0476, 0.0110, 0.0091, 0.0657, 0.0740,\n",
       "         0.0212, 0.1430, 0.0141, 0.0498, 0.0218, 0.0383, 0.0043, 0.0109, 0.1270],\n",
       "        [0.0214, 0.0358, 0.1165, 0.0535, 0.0072, 0.0417, 0.0108, 0.0090, 0.0095,\n",
       "         0.0246, 0.0186, 0.0075, 0.0043, 0.0529, 0.0155, 0.0167, 0.1209, 0.0591,\n",
       "         0.0228, 0.0402, 0.0262, 0.1602, 0.0529, 0.0032, 0.0230, 0.0293, 0.0167],\n",
       "        [0.0296, 0.0124, 0.0585, 0.0291, 0.0187, 0.0346, 0.0322, 0.0157, 0.0161,\n",
       "         0.0817, 0.0107, 0.1477, 0.0092, 0.0188, 0.0088, 0.1513, 0.0141, 0.1288,\n",
       "         0.0236, 0.0389, 0.0201, 0.0190, 0.0048, 0.0078, 0.0411, 0.0112, 0.0153],\n",
       "        [0.0296, 0.0124, 0.0585, 0.0291, 0.0187, 0.0346, 0.0322, 0.0157, 0.0161,\n",
       "         0.0817, 0.0107, 0.1477, 0.0092, 0.0188, 0.0088, 0.1513, 0.0141, 0.1288,\n",
       "         0.0236, 0.0389, 0.0201, 0.0190, 0.0048, 0.0078, 0.0411, 0.0112, 0.0153],\n",
       "        [0.0082, 0.0309, 0.0311, 0.0235, 0.0186, 0.0154, 0.0494, 0.0365, 0.0285,\n",
       "         0.0230, 0.0254, 0.0797, 0.0173, 0.0185, 0.0103, 0.0194, 0.0266, 0.0057,\n",
       "         0.0059, 0.0109, 0.0486, 0.0081, 0.0672, 0.1122, 0.0758, 0.0011, 0.2021]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY ------------------>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neuros's weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float() # Input to the network: one-hot encoding \n",
    "logits = xenc @ W # predict log-counts \n",
    "counts = logits.exp() # counts, equivalent to N \n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character \n",
    "# btw: the last 2 lines here are together called a \"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .. (indexes 0,0)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.06067225709557533\n",
      "log likelihood: -2.8022687435150146\n",
      "negative log likelihood: 2.8022687435150146\n",
      "--------\n",
      "bigram example 2: ee (indexes 5,5)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.028868859633803368\n",
      "log likelihood: -3.5449917316436768\n",
      "negative log likelihood: 3.5449917316436768\n",
      "--------\n",
      "bigram example 3: mm (indexes 13,13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "--------\n",
      "bigram example 4: mm (indexes 13,13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "--------\n",
      "bigram example 5: aa (indexes 1,1)\n",
      "input to the neural net: 1\n",
      "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
      "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
      "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.008642823435366154\n",
      "log likelihood: -4.751026153564453\n",
      "negative log likelihood: 4.751026153564453\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 3.669020891189575\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- !!! OPTIMIZATION !!! ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neuros's weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # Input to the network: one-hot encoding \n",
    "logits = xenc @ W # predict log-counts \n",
    "counts = logits.exp() # counts, equivalent to N \n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character \n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6122443675994873\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "W.grad = None \n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to the tensor\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Putting it all together -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# Create the training set of bigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    #print(ch1, ch2)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix1)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the \"network\"\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7305312156677246\n",
      "1.0994595289230347\n",
      "0.591590940952301\n",
      "0.3783233165740967\n",
      "0.2760242521762848\n",
      "0.21673227846622467\n",
      "0.17668212950229645\n",
      "0.14805859327316284\n",
      "0.12695103883743286\n",
      "0.11091091483831406\n",
      "0.09834054857492447\n",
      "0.08820056915283203\n",
      "0.07981247454881668\n",
      "0.07272743433713913\n",
      "0.06664177775382996\n",
      "0.06134545058012009\n",
      "0.056689005345106125\n",
      "0.052563346922397614\n",
      "0.048886414617300034\n",
      "0.04559497535228729\n",
      "0.04263840615749359\n",
      "0.03997547924518585\n",
      "0.037571411579847336\n",
      "0.03539661690592766\n",
      "0.03342510014772415\n",
      "0.03163433074951172\n",
      "0.03000427968800068\n",
      "0.02851726859807968\n",
      "0.027157675474882126\n",
      "0.025911647826433182\n",
      "0.02476702444255352\n",
      "0.023712987080216408\n",
      "0.022740010172128677\n",
      "0.02183980867266655\n",
      "0.02100490592420101\n",
      "0.020228860899806023\n",
      "0.019505925476551056\n",
      "0.01883106119930744\n",
      "0.018199801445007324\n",
      "0.017608141526579857\n",
      "0.01705247536301613\n",
      "0.016529791057109833\n",
      "0.016037285327911377\n",
      "0.015572436153888702\n",
      "0.015133005566895008\n",
      "0.01471701916307211\n",
      "0.01432262733578682\n",
      "0.013948258943855762\n",
      "0.013592429459095001\n",
      "0.013253780081868172\n",
      "0.012931163422763348\n",
      "0.012623472139239311\n",
      "0.01232968084514141\n",
      "0.01204880140721798\n",
      "0.011780206114053726\n",
      "0.011522974818944931\n",
      "0.011276456527411938\n",
      "0.011039973236620426\n",
      "0.010812968015670776\n",
      "0.010594917461276054\n",
      "0.010385227389633656\n",
      "0.010183470323681831\n",
      "0.009989241138100624\n",
      "0.009802141226828098\n",
      "0.009621700271964073\n",
      "0.009447712451219559\n",
      "0.009279651567339897\n",
      "0.009117470122873783\n",
      "0.008960670791566372\n",
      "0.008809063583612442\n",
      "0.008662458509206772\n",
      "0.00852053239941597\n",
      "0.008383125066757202\n",
      "0.008249959908425808\n",
      "0.00812090840190649\n",
      "0.007995763793587685\n",
      "0.007874352857470512\n",
      "0.007756506092846394\n",
      "0.0076421028934419155\n",
      "0.007530964445322752\n",
      "0.00742298923432827\n",
      "0.0073179700411856174\n",
      "0.007215890567749739\n",
      "0.007116593886166811\n",
      "0.007019936107099056\n",
      "0.0069258552975952625\n",
      "0.006834228057414293\n",
      "0.006744944024831057\n",
      "0.006657945457845926\n",
      "0.006573149003088474\n",
      "0.006490517873317003\n",
      "0.006409808527678251\n",
      "0.00633115554228425\n",
      "0.006254382431507111\n",
      "0.00617942912504077\n",
      "0.006106172222644091\n",
      "0.0060347141698002815\n",
      "0.005964815150946379\n",
      "0.005896552465856075\n",
      "0.005829818081110716\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # Input to the network: one-hot encoding \n",
    "    logits = xenc @ W # predict log-counts \n",
    "    counts = logits.exp() # counts, equivalent to N \n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character \n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None \n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0233e+01, -3.4948e-01, -1.6471e-01, -1.1490e+00,  1.0075e-01,\n",
       "         -1.6667e-01, -1.5781e+00,  3.5507e-01, -7.2939e-02,  5.7525e-01,\n",
       "         -5.6067e-01,  4.9117e-01, -4.3115e-01, -5.2578e-01,  8.7152e-01,\n",
       "          1.0755e+00,  9.7041e-01, -1.6548e+00,  4.1000e-01, -9.0273e-01,\n",
       "          6.3053e-01, -2.7062e-01, -1.5127e+00,  2.3252e-01, -2.0246e-01,\n",
       "          1.2013e+00,  1.2035e+00],\n",
       "        [-8.5792e-01,  9.5897e+00, -1.5308e-01, -1.2006e+00,  7.0558e-02,\n",
       "         -3.1374e-01,  2.5057e-01, -9.6801e-01, -1.0088e+00, -1.8696e+00,\n",
       "          2.4092e-01, -1.3362e+00,  2.3387e-01, -1.1068e+00, -5.1434e-01,\n",
       "         -6.0140e-01, -1.3564e-01, -1.4266e+00,  2.1184e-01,  8.4792e-03,\n",
       "         -6.3815e-02, -3.1179e-01, -1.8071e+00, -2.7091e-01,  1.0313e-01,\n",
       "         -1.9686e-02, -1.2819e+00],\n",
       "        [-6.4292e-02, -1.0726e+00,  7.3075e+00,  1.9019e-01, -9.8884e-01,\n",
       "         -8.7184e-01, -7.4415e-02, -3.6398e-01, -1.1099e+00, -1.5795e+00,\n",
       "          5.1751e-01, -9.6370e-01,  9.6653e-01,  1.1231e+00, -9.3892e-01,\n",
       "          2.4056e-01,  2.9624e-01,  8.5578e-01, -1.1137e+00, -7.6362e-01,\n",
       "         -8.1786e-01,  9.6879e-01, -4.1925e-02,  5.5341e-01, -7.3085e-01,\n",
       "         -1.2170e-01, -1.2255e+00],\n",
       "        [ 5.2835e-01, -4.7585e-01, -1.4369e+00,  7.1392e+00, -2.3190e-02,\n",
       "          4.2095e-01, -9.8102e-01, -1.3388e+00,  3.6952e-01, -1.4018e+00,\n",
       "         -1.5081e-01, -1.3422e-01, -1.6016e+00, -8.6216e-01,  4.7993e-01,\n",
       "         -9.9179e-01, -4.9796e-01, -1.4436e+00, -1.7440e-01, -1.1210e+00,\n",
       "         -9.5909e-01, -2.1413e+00, -4.6759e-01, -1.7671e+00, -5.3093e-01,\n",
       "         -1.8731e+00, -9.6015e-01],\n",
       "        [-1.6450e+00, -3.2816e-04, -7.5355e-01,  5.2042e-02,  7.6070e+00,\n",
       "         -2.3262e+00, -8.7411e-01, -5.3375e-01, -2.2205e+00, -2.5460e-01,\n",
       "          2.5339e-01,  3.9586e-01, -7.5032e-01, -4.1405e-01, -4.1440e-01,\n",
       "         -2.1412e+00, -9.4497e-01,  9.0403e-02, -1.5573e+00, -7.0822e-01,\n",
       "          6.4969e-02,  2.8697e-01, -5.4814e-01, -5.4411e-01, -1.8107e+00,\n",
       "         -1.7020e+00, -4.5068e-02],\n",
       "        [ 1.6396e-01,  7.6801e-01,  4.8865e-02,  5.4936e-01,  1.0164e+00,\n",
       "          9.5745e+00, -7.6501e-01,  2.6657e-01, -7.3412e-01,  1.9123e-01,\n",
       "          7.0867e-01, -1.4790e-02, -5.8720e-01, -2.0226e-01, -6.3619e-01,\n",
       "          2.2380e-01,  1.6558e-01, -1.4402e+00,  8.2726e-01, -6.3536e-02,\n",
       "          5.0785e-01,  1.8871e-01,  5.2654e-01, -1.9384e+00, -5.6245e-01,\n",
       "         -2.1517e+00,  4.9091e-01],\n",
       "        [ 8.5672e-01,  9.0581e-02,  1.6179e+00, -4.3300e-01,  4.5824e-01,\n",
       "          2.1963e-01,  6.3154e+00, -7.6263e-01,  1.1403e+00,  4.8857e-01,\n",
       "          6.6337e-01,  1.3025e-01, -3.8745e-01, -4.1101e-01, -9.3436e-01,\n",
       "         -3.5470e-02,  1.2257e+00, -7.9731e-02,  8.7908e-01, -7.0219e-01,\n",
       "         -1.2851e+00,  4.4251e-01, -4.8298e-01, -1.1594e-01,  3.5436e-01,\n",
       "          5.8429e-01,  4.0178e-01],\n",
       "        [-1.2822e+00, -3.6770e-01,  2.1268e-01,  7.4209e-02,  1.0505e+00,\n",
       "         -3.9177e-01, -8.8450e-01,  6.9162e+00, -1.1760e+00, -5.7655e-01,\n",
       "         -6.1457e-01,  7.1180e-01,  8.1999e-01,  6.2630e-01,  5.4873e-01,\n",
       "         -1.2937e+00,  3.7716e-01,  4.2938e-01, -8.3243e-01,  2.5513e-01,\n",
       "         -1.5070e+00, -3.9769e-01,  4.7548e-01, -2.5590e-01, -1.0298e+00,\n",
       "         -6.0801e-01, -8.3158e-01],\n",
       "        [ 2.3106e-01, -4.1189e-01,  5.1999e-01, -1.5044e-02,  5.6326e-01,\n",
       "         -1.1866e+00, -9.5972e-01, -1.1697e-01,  8.2916e+00, -5.7014e-01,\n",
       "         -1.3351e+00,  5.0657e-01, -1.7622e+00, -6.4580e-01, -1.1508e+00,\n",
       "         -3.7258e-01, -4.8015e-01,  4.8536e-01, -8.1023e-01,  1.9565e-01,\n",
       "          1.5310e-01,  7.8372e-01, -5.6331e-01, -2.5421e-01,  1.0618e-01,\n",
       "          2.6342e-01, -1.6660e+00],\n",
       "        [-3.9972e-01,  5.2426e-01, -4.9286e-01, -1.2465e-01,  3.6051e-01,\n",
       "         -7.5752e-01, -5.9015e-01, -1.3636e+00, -2.0747e-01,  9.1018e+00,\n",
       "         -5.8441e-01, -5.9279e-01,  1.1455e-01, -1.5735e+00,  4.8982e-01,\n",
       "         -1.5768e+00,  4.0386e-01,  3.9758e-01, -3.4227e-01,  5.1053e-01,\n",
       "         -1.6421e-01, -9.6588e-02, -4.6649e-02, -1.0968e+00, -4.4161e-01,\n",
       "         -3.2509e-01, -9.8063e-01],\n",
       "        [-1.3495e-01,  7.0516e-02,  3.0674e-01, -9.3781e-01, -5.7279e-01,\n",
       "         -8.7515e-01, -1.0539e+00, -3.8233e-01, -1.5676e+00,  3.2365e-01,\n",
       "          7.1147e+00, -1.8532e-01, -7.8802e-01,  5.2118e-01, -9.0750e-01,\n",
       "          2.5848e-02, -9.7002e-01,  4.3619e-01, -1.8942e+00,  3.6089e-01,\n",
       "         -1.0963e+00,  1.7213e-01, -3.4216e-01,  1.2217e-01, -1.0485e+00,\n",
       "         -3.5708e-01, -4.6093e-01],\n",
       "        [-1.6017e+00,  3.4496e-02, -1.8170e+00, -1.2888e+00,  3.9836e-01,\n",
       "         -1.0200e+00,  2.5564e-01,  3.0826e-01,  1.6931e-01, -8.6347e-01,\n",
       "         -1.5853e+00,  7.7455e+00,  6.3229e-01, -5.7761e-01, -8.7113e-01,\n",
       "          1.1651e-01, -1.6079e-01, -5.8788e-01, -1.1107e-01, -6.9752e-02,\n",
       "          2.7124e-01, -7.5672e-01,  2.5213e-01, -1.5828e-01, -3.4093e-02,\n",
       "         -2.5269e+00, -6.7354e-01],\n",
       "        [-7.0777e-01, -2.9337e-01,  4.1236e-01, -1.1255e+00,  8.2547e-02,\n",
       "         -5.6833e-02, -6.0979e-01,  2.0701e-01,  3.0894e-01, -5.0465e-01,\n",
       "         -1.3843e+00, -9.1837e-01,  9.1491e+00, -4.9666e-02,  3.6026e-01,\n",
       "          1.1386e-01,  1.0432e+00,  7.1855e-01, -6.8165e-01, -4.5689e-01,\n",
       "          3.3709e-02,  9.3621e-01,  2.2591e-01,  7.0503e-01,  1.2178e-01,\n",
       "          3.1318e-01, -3.2448e-01],\n",
       "        [-9.4866e-02,  4.6565e-01,  2.1388e-01, -4.7264e-02,  4.1587e-01,\n",
       "         -4.4258e-01, -2.2367e-01, -2.6686e-01,  7.0904e-01, -6.0989e-01,\n",
       "         -1.3110e+00,  5.0263e-01, -8.0453e-01,  8.1580e+00, -7.0443e-01,\n",
       "         -9.4018e-01,  3.3260e-01, -8.7254e-01,  3.9500e-01, -1.5449e+00,\n",
       "         -4.1338e-01, -1.2663e+00, -7.9323e-01, -4.3021e-01,  7.0186e-01,\n",
       "          1.9202e-01, -8.3553e-01],\n",
       "        [ 7.5290e-01, -3.9730e-01,  6.3770e-01,  1.3642e-01,  4.4172e-02,\n",
       "         -2.0081e+00, -1.0027e+00, -1.0697e-02, -4.5346e-01,  1.3894e-01,\n",
       "         -8.7837e-01, -2.5921e-01, -7.7304e-01,  5.6786e-01,  9.2040e+00,\n",
       "         -8.4750e-01,  7.0225e-01, -6.7883e-01, -4.3819e-01,  4.4487e-01,\n",
       "         -8.8584e-01, -2.4719e-01, -9.1408e-01,  5.1855e-01, -6.8404e-01,\n",
       "         -1.3941e+00, -8.3873e-01],\n",
       "        [-9.0904e-01,  5.3221e-01, -1.5742e+00,  2.4511e-01,  8.3722e-02,\n",
       "         -1.1088e+00,  3.6954e-01,  8.0982e-01, -5.8447e-01, -8.9830e-01,\n",
       "         -2.1370e+00,  5.0553e-01,  2.6229e-01, -8.6322e-02, -4.3323e-01,\n",
       "          8.2876e+00, -1.1094e-01, -7.7544e-01, -3.5008e-01, -2.2295e+00,\n",
       "         -6.6557e-02,  1.6172e-01, -7.3848e-01, -1.7562e+00, -9.3374e-01,\n",
       "         -4.5614e-01,  6.3988e-01],\n",
       "        [-5.2237e-01,  1.6027e-01, -2.1645e-01,  3.3298e-01, -4.1704e-02,\n",
       "         -8.0147e-01, -2.2512e-01,  2.6964e-01, -2.7601e-01, -6.6974e-01,\n",
       "         -1.5413e-01, -5.6594e-01, -4.6601e-01, -3.6387e-01, -2.5636e+00,\n",
       "         -5.0322e-02,  5.7799e+00, -2.0715e+00, -1.0297e+00, -8.2124e-01,\n",
       "         -6.7701e-01, -9.8205e-01, -1.1048e+00, -1.1431e+00,  5.7088e-01,\n",
       "         -2.2102e-01, -1.0654e+00],\n",
       "        [ 8.4063e-01,  3.8822e-01,  4.9699e-01, -2.2418e+00, -1.1897e+00,\n",
       "         -4.8598e-01,  4.3600e-01, -1.1203e+00,  1.2854e-01, -2.1136e+00,\n",
       "         -3.6156e-01, -7.5273e-01,  7.3115e-01, -1.1878e+00, -1.3105e+00,\n",
       "          7.8481e-01,  1.2698e+00,  4.4624e+00,  1.2871e+00,  3.0597e-01,\n",
       "         -7.6400e-01, -7.4949e-01, -7.5894e-01,  7.6762e-01, -6.6979e-01,\n",
       "          1.4377e+00,  3.8801e-02],\n",
       "        [-1.7227e-01,  1.8313e-01, -5.0575e-01, -8.8808e-01,  1.0386e-01,\n",
       "         -2.7994e-01, -3.6239e-01, -1.3287e+00,  4.5229e-01,  3.9074e-01,\n",
       "         -1.1820e+00, -2.1909e+00,  1.3347e-01,  3.7949e-01, -4.8834e-01,\n",
       "          2.8640e-01, -2.7799e-01, -2.7683e-01,  8.6750e+00, -1.0103e-01,\n",
       "         -7.8299e-01, -1.5884e+00, -2.7374e+00, -6.2319e-01, -1.3257e+00,\n",
       "         -6.2789e-01,  5.0870e-01],\n",
       "        [-7.7048e-01, -6.1132e-01,  1.5621e-01,  5.5982e-01, -7.0620e-01,\n",
       "          4.7938e-01, -7.4629e-01, -7.3392e-01, -4.7836e-01,  1.3310e-01,\n",
       "         -1.0944e+00, -1.7504e+00,  7.8088e-01,  5.5991e-02, -8.2166e-01,\n",
       "         -5.3439e-01,  2.7492e-01, -1.0425e+00, -3.1832e-01,  8.4399e+00,\n",
       "          4.2874e-01,  4.5603e-01, -7.2387e-01, -2.1427e-01,  2.5511e-01,\n",
       "          1.7490e-01,  9.7085e-01],\n",
       "        [ 1.5522e+00, -2.2892e+00, -3.4661e-01, -5.8755e-02,  9.9481e-01,\n",
       "         -6.4844e-01, -6.5059e-01,  1.2597e+00, -8.1032e-01,  4.6697e-01,\n",
       "          3.9815e-01,  1.0597e+00, -9.4563e-01,  9.9761e-02, -2.5149e-01,\n",
       "          8.5315e-01,  1.1243e+00, -3.7809e-02,  9.6346e-02,  7.9499e-01,\n",
       "          8.4972e+00, -1.3854e-02,  2.6404e-01,  5.1318e-01,  7.2477e-01,\n",
       "         -9.7544e-01, -4.9678e-01],\n",
       "        [ 1.3516e-01, -6.7225e-01, -2.3262e+00,  9.7295e-01, -6.0473e-01,\n",
       "         -7.0820e-01,  9.9752e-01, -2.5364e-01, -5.9144e-01,  4.6880e-01,\n",
       "         -3.3517e-01, -1.3193e+00, -1.2555e+00,  6.8417e-02, -3.2972e-01,\n",
       "          5.8533e-02, -6.5662e-01, -7.4864e-01, -1.0275e+00,  8.4399e-01,\n",
       "         -2.1189e-01,  7.4398e+00, -1.0249e+00, -1.3155e-01, -6.0484e-01,\n",
       "          8.3988e-01,  7.1228e-01],\n",
       "        [ 1.9917e-01, -4.3813e-01,  5.4766e-01, -1.0302e+00, -5.3167e-01,\n",
       "         -1.8535e+00,  1.6805e-01, -7.1926e-01, -9.1613e-01,  5.4461e-01,\n",
       "         -1.1167e+00,  4.2294e-02, -8.8463e-01,  7.2746e-01, -9.9244e-01,\n",
       "          2.9233e-02,  3.1447e-01,  1.7286e-02, -1.2556e+00,  1.3368e-01,\n",
       "         -1.1290e+00, -5.7838e-01,  6.9917e+00, -3.2906e-01, -5.2710e-01,\n",
       "         -4.0877e-01, -1.3453e+00],\n",
       "        [ 1.1487e+00, -3.6832e-01, -1.4211e+00,  5.5504e-01,  6.5753e-01,\n",
       "         -6.3390e-03,  8.2417e-02,  5.3078e-01, -9.1933e-01,  2.7050e-02,\n",
       "         -5.0728e-01, -3.8243e-01, -9.2960e-02,  8.3520e-01, -9.0916e-01,\n",
       "         -9.6531e-01,  7.1269e-01, -7.0166e-01, -2.6437e-01, -8.6030e-01,\n",
       "          1.1333e+00,  3.2376e-01,  1.2972e-01,  6.1295e+00,  6.9698e-01,\n",
       "          2.0103e-01,  3.4797e-01],\n",
       "        [ 1.5035e-02, -8.6581e-01, -4.5143e-01,  1.0596e-01, -1.6677e+00,\n",
       "          6.5527e-01,  1.1205e-01, -6.8255e-02,  1.0562e-01, -1.2004e-01,\n",
       "          8.6449e-01, -9.1422e-01, -3.8048e-01, -9.6835e-01, -9.3861e-01,\n",
       "         -1.1379e+00, -3.2306e-01,  4.0291e-01, -1.3331e-02,  6.7126e-01,\n",
       "          1.0135e+00, -3.1074e-01, -2.8839e-02,  8.1739e-01,  5.6394e+00,\n",
       "         -8.3617e-01,  4.7700e-01],\n",
       "        [ 4.4332e-01, -6.7502e-01, -5.6310e-01, -1.0680e-01,  1.2711e+00,\n",
       "         -4.6083e-01,  1.5101e-01,  1.3818e+00,  9.1371e-01, -6.9535e-01,\n",
       "         -6.8579e-01, -6.7140e-01, -1.6774e-01, -1.0131e+00, -1.0246e+00,\n",
       "         -3.9857e-01,  6.6792e-01, -8.0017e-01, -2.6986e-02, -4.3855e-01,\n",
       "          1.3598e+00,  7.0056e-01, -9.2212e-01,  1.1164e+00, -2.7244e-01,\n",
       "          8.9531e+00, -3.7742e-01],\n",
       "        [ 6.4215e-01,  1.1054e-02, -8.4681e-01, -1.7303e+00, -2.9512e-01,\n",
       "         -6.2359e-01, -7.2871e-01,  5.0462e-02, -1.6010e-01,  7.9167e-01,\n",
       "         -7.2644e-01, -1.6666e-01, -7.5088e-01, -4.3455e-02, -2.2273e-01,\n",
       "          2.6001e-01,  2.9871e-01,  1.1666e-02,  5.4536e-01,  2.6053e-01,\n",
       "          4.3936e-01,  1.8313e-01,  1.1557e-01,  1.1710e+00,  8.1158e-01,\n",
       "         -3.5352e-01,  7.2971e+00]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
